use logos::Logos;
use unicode_xid::UnicodeXID;
pub use kestrel_span::{Span, Spanned};

/// Check if a string is a valid Unicode identifier
fn is_valid_identifier(lex: &mut logos::Lexer<Token>) -> bool {
    let slice = lex.slice();
    let mut chars = slice.chars();

    // First character must be XID_Start or underscore
    if let Some(first) = chars.next() {
        if !first.is_xid_start() && first != '_' {
            return false;
        }
    } else {
        return false;
    }

    // Remaining characters must be XID_Continue
    chars.all(|c| c.is_xid_continue())
}

/// Parse nested block comments and return the full comment as a token
fn parse_block_comment(lex: &mut logos::Lexer<Token>) -> bool {
    let remainder = lex.remainder();
    let mut depth = 1;
    let mut chars = remainder.chars();
    let mut offset = 0;

    while let Some(c) = chars.next() {
        offset += c.len_utf8();

        if c == '/' {
            if let Some('*') = chars.clone().next() {
                chars.next();
                offset += 1;
                depth += 1;
            }
        } else if c == '*' {
            if let Some('/') = chars.clone().next() {
                chars.next();
                offset += 1;
                depth -= 1;
                if depth == 0 {
                    lex.bump(offset);
                    return true;
                }
            }
        }
    }

    // Unclosed comment - bump to end
    lex.bump(offset);
    true
}

#[derive(Logos, Debug, Clone, PartialEq, Eq, Hash)]
pub enum Token {
    // ===== Trivia =====
    // Whitespace and comments are emitted as tokens so rowan can calculate
    // correct source positions. The parser treats these as trivia.
    #[regex(r"[ \t\n\f]+")]
    Whitespace,

    #[regex(r"//[^\n]*")]
    LineComment,

    #[regex(r"/\*", parse_block_comment)]
    BlockComment,

    // ===== Literals =====
    // Match potential Unicode identifiers and validate with XID rules
    #[regex(r"[\p{L}_][\p{L}\p{N}_]*", is_valid_identifier)]
    Identifier,

    #[regex(r#""([^"\\]|\\.)*""#)]
    String,

    #[regex(r"[0-9]+")]
    Integer,

    #[regex(r"[0-9]+\.[0-9]+([eE][+-]?[0-9]+)?")]
    Float,

    #[token("true")]
    #[token("false")]
    Boolean,

    #[token("null")]
    Null,

    // ===== Declaration Keywords =====
    #[token("fileprivate")]
    Fileprivate,

    #[token("func")]
    Func,

    #[token("import")]
    Import,

    #[token("internal")]
    Internal,

    #[token("let")]
    Let,

    #[token("module")]
    Module,

    #[token("private")]
    Private,

    #[token("protocol")]
    Protocol,

    #[token("public")]
    Public,

    #[token("static")]
    Static,

    #[token("struct")]
    Struct,

    #[token("type")]
    Type,

    #[token("var")]
    Var,

    // ===== Statement Keywords =====
    #[token("as")]
    As,

    #[token("else")]
    Else,

    #[token("if")]
    If,

    // ===== Braces =====
    #[token("(")]
    LParen,

    #[token(")")]
    RParen,

    #[token("{")]
    LBrace,

    #[token("}")]
    RBrace,

    #[token("[")]
    LBracket,

    #[token("]")]
    RBracket,

    // ===== Punctuation =====
    #[token(";")]
    Semicolon,

    #[token(",")]
    Comma,

    #[token(".")]
    Dot,

    #[token(":")]
    Colon,

    #[token("!")]
    Bang,

    // ===== Operators =====
    #[token("=")]
    Equals,

    #[token("+")]
    Plus,

    #[token("-")]
    Minus,

    #[token("->")]
    Arrow,

    #[token("*")]
    Star,

    #[token("/")]
    Slash,
}

pub type SpannedToken = Spanned<Token>;

/// Lex source code and return an iterator of tokens with their spans
pub fn lex(source: &str) -> impl Iterator<Item = Result<SpannedToken, Spanned<()>>> + '_ {
    Token::lexer(source).spanned().map(|(token, span)| {
        token
            .map(|t| Spanned::new(t, span.clone()))
            .map_err(|_| Spanned::new((), span))
    })
}

#[cfg(test)]
mod tests {
    use super::*;

    /// Filter out trivia tokens (whitespace and comments) for tests
    fn filter_trivia(tokens: Vec<Result<Spanned<Token>, Spanned<()>>>) -> Vec<Spanned<Token>> {
        tokens
            .into_iter()
            .filter_map(|t| t.ok())
            .filter(|t| !matches!(t.value, Token::Whitespace | Token::LineComment | Token::BlockComment))
            .collect()
    }

    #[test]
    fn test_lexer() {
        let source = "func main() { let x = 42; }";
        let tokens = filter_trivia(lex(source).collect());

        assert!(tokens.len() > 0);

        // First token should be 'func' at position 0..4
        assert_eq!(tokens[0].value, Token::Func);
        assert_eq!(tokens[0].span, 0..4);
    }

    #[test]
    fn test_spans() {
        let source = "let x = 42";
        let tokens = filter_trivia(lex(source).collect());

        // Verify spans don't overlap and cover the source
        assert_eq!(tokens[0].span, 0..3);   // "let"
        assert_eq!(tokens[1].span, 4..5);   // "x"
        assert_eq!(tokens[2].span, 6..7);   // "="
        assert_eq!(tokens[3].span, 8..10);  // "42"
    }

    #[test]
    fn test_literals() {
        // Test string literals
        let source = r#""hello world""#;
        let tokens = filter_trivia(lex(source).collect());
        assert_eq!(tokens[0].value, Token::String);

        // Test integer literals
        let source = "42";
        let tokens = filter_trivia(lex(source).collect());
        assert_eq!(tokens[0].value, Token::Integer);

        // Test float literals
        let source = "3.14 2.5e10 1.0E-5";
        let tokens = filter_trivia(lex(source).collect());
        assert_eq!(tokens[0].value, Token::Float);
        assert_eq!(tokens[1].value, Token::Float);
        assert_eq!(tokens[2].value, Token::Float);

        // Test boolean literals
        let source = "true false";
        let tokens = filter_trivia(lex(source).collect());
        assert_eq!(tokens[0].value, Token::Boolean);
        assert_eq!(tokens[1].value, Token::Boolean);

        // Test null literal
        let source = "null";
        let tokens = filter_trivia(lex(source).collect());
        assert_eq!(tokens[0].value, Token::Null);
    }

    #[test]
    fn test_module_declaration() {
        let source = "module A.B.C";
        let tokens = filter_trivia(lex(source).collect());

        assert_eq!(tokens.len(), 6);
        assert_eq!(tokens[0].value, Token::Module);
        assert_eq!(tokens[1].value, Token::Identifier);
        assert_eq!(tokens[2].value, Token::Dot);
        assert_eq!(tokens[3].value, Token::Identifier);
        assert_eq!(tokens[4].value, Token::Dot);
        assert_eq!(tokens[5].value, Token::Identifier);
    }

    #[test]
    fn test_unicode_identifiers() {
        // Test various Unicode identifier patterns
        let source = "let café = 42";
        let tokens = filter_trivia(lex(source).collect());

        assert_eq!(tokens.len(), 4);
        assert_eq!(tokens[0].value, Token::Let);
        assert_eq!(tokens[1].value, Token::Identifier); // café
        assert_eq!(tokens[2].value, Token::Equals);
        assert_eq!(tokens[3].value, Token::Integer);

        // Test Greek identifiers
        let source = "func αβγ() { }";
        let tokens = filter_trivia(lex(source).collect());

        assert_eq!(tokens[0].value, Token::Func);
        assert_eq!(tokens[1].value, Token::Identifier); // αβγ

        // Test mixed scripts
        let source = "let _hello世界 = 42";
        let tokens = filter_trivia(lex(source).collect());

        assert_eq!(tokens[1].value, Token::Identifier); // _hello世界
    }

    #[test]
    fn test_line_comments() {
        let source = r#"
            let x = 42; // This is a comment
            let y = 10; // Another comment
        "#;
        let tokens = filter_trivia(lex(source).collect());

        // Comments should be skipped
        // Tokens: let x = 42 ; let y = 10 ;
        assert_eq!(tokens.len(), 10);
        assert_eq!(tokens[0].value, Token::Let);
        assert_eq!(tokens[1].value, Token::Identifier); // x
        assert_eq!(tokens[2].value, Token::Equals);
        assert_eq!(tokens[3].value, Token::Integer); // 42
        assert_eq!(tokens[4].value, Token::Semicolon);
        assert_eq!(tokens[5].value, Token::Let);
        assert_eq!(tokens[6].value, Token::Identifier); // y
        assert_eq!(tokens[7].value, Token::Equals);
        assert_eq!(tokens[8].value, Token::Integer); // 10
        assert_eq!(tokens[9].value, Token::Semicolon);
    }

    #[test]
    fn test_block_comments() {
        let source = r#"
            let x = /* comment */ 42;
            /* multi
               line
               comment */
            let y = 10;
        "#;
        let tokens = filter_trivia(lex(source).collect());

        // Comments should be skipped
        // Tokens: let x = 42 ; let y = 10 ;
        assert_eq!(tokens.len(), 10);
        assert_eq!(tokens[0].value, Token::Let);
        assert_eq!(tokens[1].value, Token::Identifier); // x
        assert_eq!(tokens[2].value, Token::Equals);
        assert_eq!(tokens[3].value, Token::Integer); // 42
        assert_eq!(tokens[4].value, Token::Semicolon);
        assert_eq!(tokens[5].value, Token::Let);
        assert_eq!(tokens[6].value, Token::Identifier); // y
        assert_eq!(tokens[7].value, Token::Equals);
        assert_eq!(tokens[8].value, Token::Integer); // 10
        assert_eq!(tokens[9].value, Token::Semicolon);
    }

    #[test]
    fn test_nested_comments() {
        let source = r#"
            let x = /* outer /* inner */ still outer */ 42;
            let y = /* /* /* deeply */ nested */ comments */ 10;
        "#;
        let tokens = filter_trivia(lex(source).collect());

        // All nested comments should be properly handled
        // Tokens: let x = 42 ; let y = 10 ;
        assert_eq!(tokens.len(), 10);
        assert_eq!(tokens[0].value, Token::Let);
        assert_eq!(tokens[1].value, Token::Identifier); // x
        assert_eq!(tokens[2].value, Token::Equals);
        assert_eq!(tokens[3].value, Token::Integer); // 42
        assert_eq!(tokens[4].value, Token::Semicolon);
        assert_eq!(tokens[5].value, Token::Let);
        assert_eq!(tokens[6].value, Token::Identifier); // y
        assert_eq!(tokens[7].value, Token::Equals);
        assert_eq!(tokens[8].value, Token::Integer); // 10
        assert_eq!(tokens[9].value, Token::Semicolon);
    }

    #[test]
    fn test_comments_dont_affect_strings() {
        let source = r#"let s = "// not a comment";"#;
        let tokens = filter_trivia(lex(source).collect());

        assert_eq!(tokens.len(), 5); // let s = "..." ;
        assert_eq!(tokens[0].value, Token::Let);
        assert_eq!(tokens[1].value, Token::Identifier); // s
        assert_eq!(tokens[2].value, Token::Equals);
        assert_eq!(tokens[3].value, Token::String);
        assert_eq!(tokens[4].value, Token::Semicolon);
    }

    #[test]
    fn test_import_keyword() {
        let source = "import A.B.C";
        let tokens = filter_trivia(lex(source).collect());

        assert_eq!(tokens.len(), 6);
        assert_eq!(tokens[0].value, Token::Import);
        assert_eq!(tokens[1].value, Token::Identifier); // A
        assert_eq!(tokens[2].value, Token::Dot);
        assert_eq!(tokens[3].value, Token::Identifier); // B
        assert_eq!(tokens[4].value, Token::Dot);
        assert_eq!(tokens[5].value, Token::Identifier); // C
    }

    #[test]
    fn test_import_with_as() {
        let source = "import A.B.C as D";
        let tokens = filter_trivia(lex(source).collect());

        assert_eq!(tokens.len(), 8);
        assert_eq!(tokens[0].value, Token::Import);
        assert_eq!(tokens[1].value, Token::Identifier); // A
        assert_eq!(tokens[2].value, Token::Dot);
        assert_eq!(tokens[3].value, Token::Identifier); // B
        assert_eq!(tokens[4].value, Token::Dot);
        assert_eq!(tokens[5].value, Token::Identifier); // C
        assert_eq!(tokens[6].value, Token::As);
        assert_eq!(tokens[7].value, Token::Identifier); // D
    }

    #[test]
    fn test_import_with_list() {
        let source = "import A.B.C.(D, E)";
        let tokens = filter_trivia(lex(source).collect());

        assert_eq!(tokens.len(), 12);
        assert_eq!(tokens[0].value, Token::Import);
        assert_eq!(tokens[1].value, Token::Identifier); // A
        assert_eq!(tokens[2].value, Token::Dot);
        assert_eq!(tokens[3].value, Token::Identifier); // B
        assert_eq!(tokens[4].value, Token::Dot);
        assert_eq!(tokens[5].value, Token::Identifier); // C
        assert_eq!(tokens[6].value, Token::Dot);
        assert_eq!(tokens[7].value, Token::LParen);
        assert_eq!(tokens[8].value, Token::Identifier); // D
        assert_eq!(tokens[9].value, Token::Comma);
        assert_eq!(tokens[10].value, Token::Identifier); // E
        assert_eq!(tokens[11].value, Token::RParen);
    }

    #[test]
    fn test_type_alias_declaration() {
        let source = "type Alias = Aliased;";
        let tokens = filter_trivia(lex(source).collect());

        assert_eq!(tokens.len(), 5);
        assert_eq!(tokens[0].value, Token::Type);
        assert_eq!(tokens[1].value, Token::Identifier); // Alias
        assert_eq!(tokens[2].value, Token::Equals);
        assert_eq!(tokens[3].value, Token::Identifier); // Aliased
        assert_eq!(tokens[4].value, Token::Semicolon);
    }

    #[test]
    fn test_type_alias_with_visibility() {
        let source = "public type Alias = Aliased;";
        let tokens = filter_trivia(lex(source).collect());

        assert_eq!(tokens.len(), 6);
        assert_eq!(tokens[0].value, Token::Public);
        assert_eq!(tokens[1].value, Token::Type);
        assert_eq!(tokens[2].value, Token::Identifier); // Alias
        assert_eq!(tokens[3].value, Token::Equals);
        assert_eq!(tokens[4].value, Token::Identifier); // Aliased
        assert_eq!(tokens[5].value, Token::Semicolon);
    }
}
